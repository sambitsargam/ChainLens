# ğŸ”— ChainLens

Compare Wikipedia vs Grokipedia articles using **3 AI models in parallel** and publish verified insights to the OriginTrail DKG.

## âœ¨ Key Features

- **Multi-Model LLM Analysis** - OpenAI, Gemini, Grok working together in parallel
- **Consensus Voting** - Majority voting system for high-confidence results
- **DKG Publishing** - Immutable knowledge assets on OriginTrail blockchain
- **Clean UI** - Text-focused interface, no distractions
- **Real-time Classification** - Detects: factual inconsistencies, missing context, bias, hallucinations

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js v18+
- API Keys: OpenAI, Google Gemini, Grok
- OriginTrail Edge Node (local or remote)

### Setup

**1. Backend**
```bash
cd backend
npm install
cp .env.example .env
# Edit .env with your API keys
npm start  # Runs on port 3001
```

**2. Frontend**
```bash
cd frontend
npm install
npm run dev  # Runs on port 5173
```

### Usage
1. Open http://localhost:5173
2. Select a topic (AI, Blockchain, etc.)
3. Click "Compare with Wikipedia"
4. View results with all 3 model votes
5. Publish to OriginTrail DKG

---

## ğŸ“Š How It Works

```
Wikipedia Article
       â”‚
       â”œâ”€â†’ [Extract Text] â†â”€ Grokipedia Article
       â”‚
       â–¼
Identify Discrepancies
       â”‚
       â”œâ”€â†’ [OpenAI]  â”
       â”œâ”€â†’ [Gemini]  â”œâ”€â†’ Majority Vote â†’ Consensus
       â”œâ”€â†’ [Grok]    â”˜
       â”‚
       â–¼
Generate Community Note
       â”‚
       â–¼
Publish to DKG (OriginTrail)
```

**Result**: Alignment score + Discrepancy classifications + UAL

---

## ğŸ”§ Environment Setup

### Backend `.env`
```env
PORT=3001
NODE_ENV=development
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=AIzaSy...
GROK_API_KEY=gsk_...
```

### Frontend `.env`
```env
VITE_API_BASE_URL=http://localhost:3001
```

---

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ src/routes/
â”‚   â”œâ”€â”€ classify.js        # 3-model classification endpoint
â”‚   â”œâ”€â”€ llm-debug.js       # Testing/debugging endpoints
â”‚   â”œâ”€â”€ premium.js         # Premium features
â”‚   â””â”€â”€ scraper.js         # Content fetchers
â”œâ”€â”€ src/services/
â”‚   â”œâ”€â”€ llm.js             # LLM service (all 3 models)
â”‚   â””â”€â”€ publisher.js       # DKG publisher
â””â”€â”€ .env

frontend/
â”œâ”€â”€ src/pages/
â”‚   â”œâ”€â”€ ComparisonDashboard.jsx
â”‚   â””â”€â”€ LandingPage.jsx
â”œâ”€â”€ src/services/
â”‚   â”œâ”€â”€ wikipedia.js
â”‚   â”œâ”€â”€ grokipedia.js
â”‚   â”œâ”€â”€ comparison.js
â”‚   â””â”€â”€ dkg.js
â””â”€â”€ .env
```

---

## ğŸ§ª Testing

### Quick Test
```bash
./test-llm.sh
```

### Manual Test
```bash
# Check API configuration
curl http://localhost:3001/api/llm-debug/status

# Test all 3 models
curl -X POST http://localhost:3001/api/llm-debug/test-all \
  -H "Content-Type: application/json" \
  -d '{"claim":"Test","context":"Context"}'

# Test classification
curl -X POST http://localhost:3001/api/classify \
  -H "Content-Type: application/json" \
  -d '{"discrepancies":["Claim"],"context":"Context"}'
```

---

## ğŸ“ˆ API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/classify` | POST | Classify discrepancies with all 3 models |
| `/api/llm-debug/status` | GET | Check API key configuration |
| `/api/llm-debug/test-all` | POST | Test all 3 models |
| `/api/analysis/advanced` | POST | Premium multi-claim analysis |

---

## ğŸ¯ Classification Categories

- **Factual Inconsistency** - Claims contradict established facts
- **Missing Context** - True but incomplete information
- **Hallucination** - False information generated by source
- **Bias** - Subjective or prejudiced framing
- **Aligned** - Both sources agree

---

## ğŸ” Security

- **API Keys**: Use environment variables only
- **CORS**: Configure for production domains
- **Rate Limiting**: Built-in with exponential backoff
- **DKG Keys**: Keep private keys secure

---

## ğŸ“š Documentation

- **[QUICK_REFERENCE.md](./QUICK_REFERENCE.md)** - 30-second overview
- **[IMPLEMENTATION_COMPLETE.md](./IMPLEMENTATION_COMPLETE.md)** - Technical details
- **[LLM_TESTING_GUIDE.md](./LLM_TESTING_GUIDE.md)** - Testing procedures
- **[MULTI_MODEL_LLM_GUIDE.md](./MULTI_MODEL_LLM_GUIDE.md)** - Model integration

---

## ğŸš€ Production

**Backend**:
- Set `NODE_ENV=production`
- Use process manager (PM2)
- Enable logging and monitoring
- Configure reverse proxy (nginx)

**Frontend**:
- Run `npm run build`
- Serve via CDN
- Enable compression

---

## ğŸ“Š Expected Output

```
ğŸ¤– LLM Analysis Results

3 models analyzed âœ…

Consensus: Factual Inconsistency
Confidence: 95%

Model Votes:
âœ“ OpenAI: Factual Inconsistency
âœ“ Gemini: Factual Inconsistency  
âœ“ Grok: Factual Inconsistency

Published to DKG:
UAL: did:dkg:otp/0x1234.../12345
```

---

## ğŸ¤ Contributing

Areas for improvement:
- Additional LLM providers
- Enhanced text comparison algorithms
- Advanced DKG queries
- Database integration
- Performance optimization

---

## ğŸ“„ License

MIT License - see [LICENSE](./LICENSE)

---

## ğŸ”— Resources

- [OriginTrail DKG](https://www.origintrail.io/)
- [OpenAI API](https://platform.openai.com/)
- [Google Gemini](https://ai.google.dev/)
- [Grok (xAI)](https://www.x.ai/)

---

**Built for Truth** â€¢ Multi-Model LLM Consensus â€¢ OriginTrail DKG â€¢ 2025

#!/usr/bin/env node

/**
 * ü§ñ ChainLens Multi-Model LLM System Verification
 * Checks if all 3 models (OpenAI, Gemini, Grok) are properly configured
 */

import path from 'path';
import { fileURLToPath } from 'url';
import fs from 'fs';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

console.log('üîç ChainLens Multi-Model LLM System Verification');
console.log('‚ïê'.repeat(50));

// Check 1: Frontend LLM Service
console.log('\nüì± Frontend Configuration:');
const frontendLlmPath = path.join(__dirname, 'frontend/src/services/llm.js');
if (fs.existsSync(frontendLlmPath)) {
  const content = fs.readFileSync(frontendLlmPath, 'utf-8');
  const hasOpenAI = content.includes('classifyWithOpenAI');
  const hasGemini = content.includes('classifyWithGemini');
  const hasGrok = content.includes('classifyWithGrok');
  const hasConsensus = content.includes('Promise.allSettled');
  
  console.log(`  ‚úÖ Frontend LLM Service: ${frontendLlmPath}`);
  console.log(`     ‚Ä¢ OpenAI Support: ${hasOpenAI ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Gemini Support: ${hasGemini ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Grok Support: ${hasGrok ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Consensus Mode: ${hasConsensus ? '‚úì (Parallel)' : '‚úó'}`);
} else {
  console.log(`  ‚ùå Frontend LLM Service not found: ${frontendLlmPath}`);
}

// Check 2: Backend LLM Service
console.log('\nüñ•Ô∏è  Backend Configuration:');
const backendLlmPath = path.join(__dirname, 'backend/src/services/llm.js');
if (fs.existsSync(backendLlmPath)) {
  const content = fs.readFileSync(backendLlmPath, 'utf-8');
  const hasOpenAI = content.includes('classifyWithOpenAI');
  const hasGemini = content.includes('classifyWithGemini');
  const hasGrok = content.includes('classifyWithGrok');
  const hasConsensus = content.includes('classifyWithConsensus');
  const hasSimple = content.includes('classifySimple');
  
  console.log(`  ‚úÖ Backend LLM Service: ${backendLlmPath}`);
  console.log(`     ‚Ä¢ OpenAI Support: ${hasOpenAI ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Gemini Support: ${hasGemini ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Grok Support: ${hasGrok ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Consensus Function: ${hasConsensus ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Fallback Function: ${hasSimple ? '‚úì' : '‚úó'}`);
} else {
  console.log(`  ‚ùå Backend LLM Service not found: ${backendLlmPath}`);
}

// Check 3: Premium Endpoint Integration
console.log('\nüîå API Endpoint Configuration:');
const premiumPath = path.join(__dirname, 'backend/src/routes/premium.js');
if (fs.existsSync(premiumPath)) {
  const content = fs.readFileSync(premiumPath, 'utf-8');
  const hasLlmImport = content.includes('llm.js');
  const hasConsensusCall = content.includes('classifyWithConsensus');
  
  console.log(`  ‚úÖ Premium Route: ${premiumPath}`);
  console.log(`     ‚Ä¢ LLM Service Import: ${hasLlmImport ? '‚úì' : '‚úó'}`);
  console.log(`     ‚Ä¢ Consensus Integration: ${hasConsensusCall ? '‚úì' : '‚úó'}`);
} else {
  console.log(`  ‚ùå Premium Route not found: ${premiumPath}`);
}

// Check 4: Environment Configuration
console.log('\nüîê Environment Configuration:');
const frontendEnvPath = path.join(__dirname, 'frontend/.env');
const backendEnvPath = path.join(__dirname, 'backend/.env');

const checkEnv = (path, label) => {
  if (fs.existsSync(path)) {
    const content = fs.readFileSync(path, 'utf-8');
    const hasOpenAI = content.includes('OPENAI_API_KEY') && !content.includes('OPENAI_API_KEY=');
    const hasGemini = content.includes('GEMINI_API_KEY') && !content.includes('GEMINI_API_KEY=');
    const hasGrok = content.includes('GROK_API_KEY') && !content.includes('GROK_API_KEY=');
    
    console.log(`  ‚úÖ ${label}: Found`);
    console.log(`     ‚Ä¢ OpenAI Key: ${hasOpenAI ? '‚úì Configured' : '‚ö† Missing or Empty'}`);
    console.log(`     ‚Ä¢ Gemini Key: ${hasGemini ? '‚úì Configured' : '‚ö† Missing or Empty'}`);
    console.log(`     ‚Ä¢ Grok Key: ${hasGrok ? '‚úì Configured' : '‚ö† Missing or Empty'}`);
  } else {
    console.log(`  ‚ö†Ô∏è  ${label}: Not found`);
  }
};

checkEnv(frontendEnvPath, 'Frontend .env');
checkEnv(backendEnvPath, 'Backend .env');

// Summary
console.log('\n' + '‚ïê'.repeat(50));
console.log('üìä System Status:');
console.log('‚ïê'.repeat(50));

const checks = [
  ['Frontend LLM Service (3 models)', fs.existsSync(frontendLlmPath)],
  ['Backend LLM Service (3 models)', fs.existsSync(backendLlmPath)],
  ['Premium Endpoint Integration', fs.existsSync(premiumPath)],
  ['Environment Configuration', fs.existsSync(frontendEnvPath) && fs.existsSync(backendEnvPath)]
];

const allPassed = checks.every(([_, result]) => result);
const passCount = checks.filter(([_, result]) => result).length;

checks.forEach(([check, passed]) => {
  console.log(`  ${passed ? '‚úÖ' : '‚ùå'} ${check}`);
});

console.log('\n' + '‚ïê'.repeat(50));
console.log(`Overall Status: ${allPassed ? '‚úÖ ALL SYSTEMS GO' : `‚ö†Ô∏è  ${passCount}/${checks.length} checks passed`}`);
console.log('‚ïê'.repeat(50));

console.log('\nüìö Multi-Model Consensus Algorithm:');
console.log('  1. All 3 models classify in PARALLEL');
console.log('  2. Collect results from available models');
console.log('  3. Vote counting for consensus label');
console.log('  4. Average confidence across models');
console.log('  5. Return consensus with all votes');

console.log('\nüîÑ Fallback Strategy:');
console.log('  ‚Ä¢ All 3 models available ‚Üí Use consensus');
console.log('  ‚Ä¢ 2 models available ‚Üí Majority vote');
console.log('  ‚Ä¢ 1 model available ‚Üí Use that result');
console.log('  ‚Ä¢ All failed ‚Üí Default classification');

console.log('\nüí° Next Steps:');
console.log('  1. Configure API keys in .env files:');
console.log('     ‚Ä¢ VITE_OPENAI_API_KEY (frontend)');
console.log('     ‚Ä¢ VITE_GEMINI_API_KEY (frontend)');
console.log('     ‚Ä¢ VITE_GROK_API_KEY (frontend)');
console.log('     ‚Ä¢ OPENAI_API_KEY (backend)');
console.log('     ‚Ä¢ GEMINI_API_KEY (backend)');
console.log('     ‚Ä¢ GROK_API_KEY (backend)');
console.log('  2. Start backend: npm start');
console.log('  3. Start frontend: npm run dev');
console.log('  4. Test consensus at: POST /api/analysis/advanced');

console.log('\n‚ú® Multi-Model System Ready for Testing!\n');
